\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrtnat}
\citation{mcclelland1995there}
\citation{hassabis2017neuroscience}
\citation{mermillod2013stability}
\citation{mccloskey1989psychology}
\citation{mccloskey1989psychology}
\citation{richardson2008critical}
\citation{parisi2019continual}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background Work}{1}{section.2}\protected@file@percent }
\newlabel{background}{{2}{1}{Background Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Catastrophic Forgetting and Continual Learning}{1}{subsection.2.1}\protected@file@percent }
\newlabel{catastrophic_forgetting_and_CL}{{2.1}{1}{Catastrophic Forgetting and Continual Learning}{subsection.2.1}{}}
\citation{kirkpatrick2017overcoming}
\citation{van2020brain}
\citation{van2019three}
\citation{van2019three}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Three Continual Learning Scenarios}{2}{subsection.2.2}\protected@file@percent }
\newlabel{three_CL_scenarios}{{2.2}{2}{Three Continual Learning Scenarios}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the three continual learing scenarios proposed by \cite  {van2019three}.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:three_CL_scenarios}{{1}{2}{Overview of the three continual learing scenarios proposed by \cite {van2019three}}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Task-Incremental Learning (Task-IL)}{2}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Domain-Incremental Learning (Domain-IL)}{2}{subsubsection.2.2.2}\protected@file@percent }
\citation{mcclelland1995there}
\citation{lesort2020continual}
\citation{lesort2020continual}
\citation{kirkpatrick2017overcoming}
\citation{zenke2017continual}
\citation{li2017learning}
\citation{shin2017continual}
\citation{lopez2017gradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Class-Incremental Learning (Class-IL)}{3}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Strategies for Continual Learning}{3}{subsection.2.3}\protected@file@percent }
\newlabel{CL_stratgies}{{2.3}{3}{Strategies for Continual Learning}{subsection.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Venn diagram of four of the most popular continual learning scenarios \cite  {lesort2020continual}.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:CL_strategies_venn_diagram}{{2}{3}{Venn diagram of four of the most popular continual learning scenarios \cite {lesort2020continual}}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Regularization Approaches}{3}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Replay Approaches}{4}{subsubsection.2.3.2}\protected@file@percent }
\newlabel{replay_approaches}{{2.3.2}{4}{Replay Approaches}{subsubsection.2.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{4}{section.3}\protected@file@percent }
\newlabel{methodology}{{3}{4}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Task Protocol}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Architectures}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Multilayer Perceptron Network}{4}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Convolutional Neural Network}{4}{subsubsection.3.2.2}\protected@file@percent }
\citation{van2019three}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Model summary of multilayer perceptron network.}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:MLP}{{3}{5}{Model summary of multilayer perceptron network}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Model summary of convolutional neural network.}}{5}{figure.4}\protected@file@percent }
\newlabel{fig:CNN}{{4}{5}{Model summary of convolutional neural network}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Continual Learning Scenarios}{5}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Permuted MNIST according to Continual Learning scenarios \cite  {van2019three}.}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:CL_scenarios}{{5}{5}{Permuted MNIST according to Continual Learning scenarios \cite {van2019three}}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Task-Incremental Learning (Task-IL)}{6}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Aside: Tasks vs. Experiences}{6}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Tasks vs. Experiences}}{6}{table.1}\protected@file@percent }
\newlabel{Tab:tasks_vs_experiences}{{1}{6}{Tasks vs. Experiences}{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Domain-Incremental Learning (Domain-IL)}{6}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Class-Incremental Learning (Class-IL)}{6}{subsubsection.3.3.4}\protected@file@percent }
\citation{kirkpatrick2017overcoming}
\citation{chaudhry2018efficient}
\citation{mcclelland1995there}
\bibdata{references}
\bibcite{mcclelland1995there}{{1}{1995}{{McClelland et~al.}}{{McClelland, McNaughton, and O'Reilly}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Strategies}{7}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Naive}{7}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}EWC}{7}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}AGEM}{7}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hyperparameter Values}}{7}{table.2}\protected@file@percent }
\newlabel{Tab:Hyperparameters}{{2}{7}{Hyperparameter Values}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Analysis}{7}{section.4}\protected@file@percent }
\bibcite{hassabis2017neuroscience}{{2}{2017}{{Hassabis et~al.}}{{Hassabis, Kumaran, Summerfield, and Botvinick}}}
\bibcite{mermillod2013stability}{{3}{2013}{{Mermillod et~al.}}{{Mermillod, Bugaiska, and Bonin}}}
\bibcite{mccloskey1989psychology}{{4}{1989}{{McCloskey and Cohen}}{{}}}
\bibcite{richardson2008critical}{{5}{2008}{{Richardson and Thomas}}{{}}}
\bibcite{parisi2019continual}{{6}{2019}{{Parisi et~al.}}{{Parisi, Kemker, Part, Kanan, and Wermter}}}
\bibcite{kirkpatrick2017overcoming}{{7}{2017}{{Kirkpatrick et~al.}}{{Kirkpatrick, Pascanu, Rabinowitz, Veness, Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska, et~al.}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Table of final results.}}{8}{figure.6}\protected@file@percent }
\newlabel{fig:results_table}{{6}{8}{Table of final results}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces MLP: Average accuracy computer after training on each task for all tasks.}}{8}{figure.7}\protected@file@percent }
\newlabel{fig:res_1}{{7}{8}{MLP: Average accuracy computer after training on each task for all tasks}{figure.7}{}}
\bibcite{van2020brain}{{8}{2020}{{van~de Ven et~al.}}{{van~de Ven, Siegelmann, and Tolias}}}
\bibcite{van2019three}{{9}{2019}{{Van~de Ven and Tolias}}{{}}}
\bibcite{lesort2020continual}{{10}{2020}{{Lesort et~al.}}{{Lesort, Lomonaco, Stoian, Maltoni, Filliat, and D{\'\i }az-Rodr{\'\i }guez}}}
\bibcite{zenke2017continual}{{11}{2017}{{Zenke et~al.}}{{Zenke, Poole, and Ganguli}}}
\bibcite{li2017learning}{{12}{2017}{{Li and Hoiem}}{{}}}
\bibcite{shin2017continual}{{13}{2017}{{Shin et~al.}}{{Shin, Lee, Kim, and Kim}}}
\bibcite{lopez2017gradient}{{14}{2017}{{Lopez-Paz and Ranzato}}{{}}}
\bibcite{chaudhry2018efficient}{{15}{2018}{{Chaudhry et~al.}}{{Chaudhry, Ranzato, Rohrbach, and Elhoseiny}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces CNN: Average accuracy computer after training on each task for all tasks.}}{9}{figure.8}\protected@file@percent }
\newlabel{fig:res_2}{{8}{9}{CNN: Average accuracy computer after training on each task for all tasks}{figure.8}{}}
\gdef \@abspage@last{9}
